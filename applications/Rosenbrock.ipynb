{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, NPZ, Statistics\n",
    "using MatrixFreeNewton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e0c2e",
   "metadata": {},
   "source": [
    "## [n-dimensional Rosenbrock](https://arxiv.org/pdf/1903.09556.pdf)\n",
    "$\\sum_{i=1}^{n-1} [100(x_{i+1} - x_i^2)^2 + (1-x_i)^2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function rosenbrockn(x)\n",
    "    f = 0.0\n",
    "    for i = 1:size(x)[1]-1\n",
    "        f += 100*(x[i+1] - x[i]^2)^2 + (1 - x[i])^2\n",
    "    end\n",
    "    return f\n",
    "end\n",
    "\n",
    "n = 10\n",
    "\n",
    "iterations = 1000\n",
    "lrsfn_rank = Int(floor(0.9*n))\n",
    "\n",
    "# Allocate logger dictionaries for seeding\n",
    "loggers_gd = Dict()\n",
    "loggers_csgd = Dict()\n",
    "loggers_newton = Dict()\n",
    "loggers_sfn = Dict()\n",
    "loggers_lrsfn = Dict()\n",
    "seed = 0\n",
    "\n",
    "\n",
    "x_0 = zeros(n)\n",
    "\n",
    "println(\"Now for gradient descent \")\n",
    "w_star_gd,logger_gd = gradientDescent(rosenbrockn,x_0,alpha = 1e-3,iterations = iterations)\n",
    "loggers_gd[seed] = logger_gd\n",
    "\n",
    "println(\"Now for curvature gradient descent \")\n",
    "w_star_gd,logger_csgd = curvatureScaledGradientDescent(rosenbrockn,x_0,iterations = iterations)\n",
    "loggers_csgd[seed] = logger_csgd\n",
    "\n",
    "print(\"Now for Newton \\n\")\n",
    "w_star_newton,logger_newton = fullNewton(rosenbrockn,x_0,alpha = 1e0,iterations=15)\n",
    "loggers_newton[seed] = logger_newton\n",
    "\n",
    "println(\"Now for low rank SFNewton with full rank Hessian \")\n",
    "w_star_newton,logger_sfn = lowRankSaddleFreeNewton(rosenbrockn,x_0,printing_frequency=iterations,\n",
    "                                                                        iterations = 15,rank = n)\n",
    "loggers_sfn[seed] = logger_sfn\n",
    "\n",
    "println(\"Now for low rank SFNewton with reduced Hessian with LRSFN rank = \",lrsfn_rank)\n",
    "w_star_newton,logger_lrsfn = lowRankSaddleFreeNewton(rosenbrockn,x_0,alpha = 1e-2,printing_frequency=10,\n",
    "                                                    gamma = 1e0,iterations = iterations,rank = lrsfn_rank,\n",
    "                                                    log_full_spectrum = true)\n",
    "loggers_lrsfn[seed] = logger_lrsfn\n",
    "\n",
    "\n",
    "println(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfc85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for post-processing\n",
    "data_dir = \"rosenbrockn_data/\"\n",
    "if ~isdir(data_dir)\n",
    "    mkdir(data_dir)\n",
    "end\n",
    "problem_name = \"rosenbrock_d=\"*string(n)\n",
    "optimizers = [\"gd\",\"csgd\",\"newton\",\"sfn\",\"lrsfn\"]\n",
    "logger_dicts = [loggers_gd,loggers_csgd,loggers_newton,loggers_sfn,loggers_lrsfn]\n",
    "\n",
    "for (optimizer,logger_dict) in zip(optimizers,logger_dicts)\n",
    "    println(\"optimizer = \",optimizer)\n",
    "    opt_losses = zeros(0)\n",
    "    for (seed,logger) in logger_dict\n",
    "        name = problem_name*optimizer*\"_\"*string(seed)\n",
    "        if optimizer == \"lrsfn\"\n",
    "            name *=\"rank_\"*string(logger.rank)\n",
    "        end\n",
    "        println(\"name = \",name)\n",
    "        # Save losses\n",
    "        npzwrite(data_dir*name*\"_losses.npy\",logger.losses)\n",
    "        min_loss = minimum(logger.losses)\n",
    "        append!(opt_losses,min_loss)\n",
    "        # If sfn save spectrum:\n",
    "        if optimizer in [\"sfn\",\"lrsfn\"]\n",
    "            \n",
    "            npzwrite(data_dir*name*\"_spectra.npy\",logger.spectra)\n",
    "        end\n",
    "        # If csgd save alphas\n",
    "        if optimizer in [\"csgd\"]\n",
    "            npzwrite(data_dir*name*\"_alphas.npy\",logger.alphas)\n",
    "        end\n",
    "    end\n",
    "    println(\"Min min loss = \",minimum(opt_losses))\n",
    "    println(\"Avg min loss = \",Statistics.mean(opt_losses))\n",
    "    println(\"Std min loss = \",Statistics.std(opt_losses,corrected = false))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
